#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Module: MagicStars.py
Author: zlamberty
Created: 2013-09-07

Description:
    I will scrape the Gatherer webpage to obtain the star ratings of cards in my
    library, and probably add them in as a value in the CSV file.  Maybe I can
    then port them back into MWS?

Usage:
    <usage>

"""

import csv
import copy
import itertools
import os
import re
import sys

from urllib import urlopen
from bs4 import BeautifulSoup


# ----------------------------- #
#   Module Constants            #
# ----------------------------- #

MAGIC_BASE_URL = 'http://gatherer.wizards.com/Pages/Search/Default.aspx?name=+[{}]'
CSV_DATA_PATH = 'ZachLibrary_new.csv'
CSV_DATA_PATH_UPDATED = 'ZachLibrary_updated.csv'

#logger = logging.getLogger("MagicStars.py")
#logger_conf = logging.Config(
#    application_name="MagicStars.py",
#    log_filename="MagicStars.py"
#).configure()
#

# ----------------------------- #
#   class definition            #
# ----------------------------- #

class MagicStars():
    """ this class is designed to collect star values from community rankings on
        the gatherer website

    """
    def __init__(self, fin=CSV_DATA_PATH, fout=CSV_DATA_PATH_UPDATED,
                 url=MAGIC_BASE_URL):
        self.fin = fin
        self.fout = fout
        self.url = url
        self.load_csv_data()

    def load_csv_data(self):
        """ load the csv data we will be updating into an appropriate object
            saved as self.cardInventory

        """
        with open(self.fin, 'r') as f:
            self.cardInventory = list(csv.DictReader(f, delimiter=";"))

    def find_all_stars(self):
        """ Cycle through the cards I own and find their star rating at
            Gatherer

        """
        for card in self.cardInventory:
            self.find_card_star(card)
        self.updated_csv_data()

    def find_card_star(self, card):
        """ Open the appropriate search URL, follow it to the correct card,
            parse it for the star rating.

        """
        try:
            page = self.proper_page(card)
            rating = self.parse_for_rating(page)
            card['Stars'] = rating
        except ValueError:
            self.cant_find_card(card)

    def cant_find_card(self, card):
        """ Indicate that we weren't able to find the proper URL, and might
            have to do it by hand

        """
        print "Can't find the info for card " + card
        self.add_rating(card, '0.000')

    def updated_csv_data(self):
        """ Save an updated CSV data file with the star ratings included """
        with open(self.fout, 'wb') as f:
            c = csv.DictWriter(f, self.cardInventory[0].keys())
            c.writeheader()
            c.writerows(self.cardInventory)

    def proper_page(self, card):
        """ Find the proper page url and return a BeautifulSoup object we
            can navigate

        """
        urlString = self.url.format(card['Name'])
        searchPage = self.open_search_url(urlString, card)
        return searchPage

    def open_search_url(self, urlString, card):
        """ Open the URL and return a BeautifulSoup object """
        soup = BeautifulSoup(urlopen(urlString))

        if self.we_found_it(soup):
            return soup
        else:
            soup = self.keep_looking(soup, card)

        return soup


    def we_found_it(self, searchPage):
        """ Check whether or not this is the correct (i.e. final) webpage """
        return (
            searchPage.find(
                'span', attrs={'class': 'textRatingValue'}
            ) != None
        )

    def keep_looking(self, searchPage, card):
        """ Find out which of the search objects is correct (if we can) and
            open / return the final page

        """
        # Find the list of possible cards, check to see if any are
        # exactly right
        tagList = searchPage.findAll(
            'a',
            attrs={'onclick': 'return CardLinkAction(event, this, \'SameWindow\');'}
        )

        for tag in tagList:
            s = str(tag.text)
            compString = str(card['Name'])

            # fuse cards
            if compString.count('/') != 0:
                compString = compString.replace('/', ' // ')
                compString += ' ({})'.format(compString[:compString.find(' // ')])

            if s.lower() == compString.lower():
                urlString = str(tag.attrs['href'])
                urlString = urlString.replace('..', 'http://gatherer.wizards.com/Pages')
                return self.open_search_url(urlString, card['Name'])

        with open('test.html', 'w') as f:
            f.write(searchPage.__repr__())
        raise ValueError("We got lost!")

    def parse_for_rating(self, page):
        """ Given a BeautifulSoup object generated by proper_page, return the
            star rating assigned by the community at Gatherer (as a string)

        """
        return page.find('span', attrs={'class': 'textRatingValue'}).text
